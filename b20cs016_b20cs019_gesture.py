# -*- coding: utf-8 -*-
"""B20CS016_B20CS019_GESTURE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/145GC1wY9dAeOz6zBKy4sh7AU0_gu7Ypj

## Setup
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
import seaborn as sns
from sklearn.metrics import precision_score as ps
from sklearn.metrics import recall_score as rs
from sklearn.metrics import f1_score as f1s
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import accuracy_score
from tqdm import tqdm
import IPython
import numpy as np
import wave
from sklearn.cluster import KMeans
import os
from PIL import Image
from numpy import asarray
import cv2
from sklearn.decomposition import PCA
import tensorflow as tf
from sklearn.metrics import accuracy_score,f1_score,roc_auc_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from keras import Input
from keras.models import Sequential,Model
from keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D,MaxPool2D,UpSampling2D,concatenate,Dropout
from sklearn.metrics import *
from matplotlib import pyplot
from tensorflow.keras.optimizers import Adam
from xgboost.sklearn import XGBClassifier
from lightgbm import LGBMClassifier

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import os
import PIL
import PIL.Image
import tensorflow as tf
import tensorflow_datasets as tfds

print(tf.__version__)

"""## Load and preprocess images

"""

base_train_path = "/content/drive/MyDrive/Embedded Project/dataset/"
base_pal_images_path = "/content/drive/MyDrive/Embedded Project/dataset/01_palm/"
base_L_images_path = "/content/drive/MyDrive/Embedded Project/dataset/02_l/"
base_fist_images_path = "/content/drive/MyDrive/Embedded Project/dataset/03_fist/"

base_fist_moved_images_path = "/content/drive/MyDrive/Embedded Project/dataset/04_fist_moved/"

base_thumb_images_path = "/content/drive/MyDrive/Embedded Project/dataset/05_thumb/"

base_index_images_path = "/content/drive/MyDrive/Embedded Project/dataset/06_index/"

base_ok_images_path = "/content/drive/MyDrive/Embedded Project/dataset/07_ok/"

base_palm_moved_images_path = "/content/drive/MyDrive/Embedded Project/dataset/08_palm_moved/"

base_c_images_path = "/content/drive/MyDrive/Embedded Project/dataset/09_c/"

base_down_images_path = "/content/drive/MyDrive/Embedded Project/dataset/10_down/"

fist_images = len(list(os.listdir(base_fist_images_path)))
print("Number of fist images: ", fist_images)

fig = plt.figure(figsize=(10,5))
rows = 2
columns = 5

palm_image=list(os.listdir(base_pal_images_path))
img1 = cv2.imread(base_pal_images_path+palm_image[0])
fig.add_subplot(rows, columns, 1)
plt.imshow(img1)
plt.title("Palm")

I_image=list(os.listdir(base_L_images_path))
img2 = cv2.imread(base_L_images_path+I_image[0])
fig.add_subplot(rows, columns, 2)
plt.imshow(img2)
plt.title("L")


fist_image=list(os.listdir(base_fist_images_path))
img3 = cv2.imread(base_fist_images_path+fist_image[0])
fig.add_subplot(rows, columns, 3)
plt.imshow(img3)
plt.title("Fist")

fist_moved_image=list(os.listdir(base_fist_moved_images_path))
img3 = cv2.imread(base_fist_moved_images_path+fist_moved_image[0])
fig.add_subplot(rows, columns, 4)
plt.imshow(img3)
plt.title("Fist Moved")

thumb_image=list(os.listdir(base_thumb_images_path))
img3 = cv2.imread(base_thumb_images_path+thumb_image[0])
fig.add_subplot(rows, columns, 5)
plt.imshow(img3)
plt.title("Thumb")

index_image=list(os.listdir(base_index_images_path))
img3 = cv2.imread(base_index_images_path+index_image[0])
fig.add_subplot(rows, columns, 6)
plt.imshow(img3)
plt.title("Index")

ok_image=list(os.listdir(base_ok_images_path))
img3 = cv2.imread(base_ok_images_path+ok_image[0])
fig.add_subplot(rows, columns, 7)
plt.imshow(img3)
plt.title("ok")

palm_moved_image=list(os.listdir(base_palm_moved_images_path))
img3 = cv2.imread(base_palm_moved_images_path+palm_moved_image[0])
fig.add_subplot(rows, columns, 8)
plt.imshow(img3)
plt.title("Palm moved")

C_image=list(os.listdir(base_c_images_path))
img3 = cv2.imread(base_c_images_path+C_image[0])
fig.add_subplot(rows, columns, 9)
plt.imshow(img3)
plt.title("C")

down_image=list(os.listdir(base_down_images_path))
img3 = cv2.imread(base_down_images_path+down_image[0])
fig.add_subplot(rows, columns, 10)
plt.imshow(img3)
plt.title("Down")

"""## Create Dataset"""

batch_size = 32
img_height = 224
img_width = 224

train_ds = tf.keras.utils.image_dataset_from_directory(
  base_train_path,
  validation_split=0.2,
  subset="training",
  color_mode='grayscale',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  base_train_path,
  validation_split=0.2,
  subset="validation",
  color_mode='grayscale',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

train_ds_normal = tf.keras.utils.image_dataset_from_directory(
  base_train_path,
  validation_split=0.2,
  subset="training",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds_normal = tf.keras.utils.image_dataset_from_directory(
  base_train_path,
  validation_split=0.2,
  subset="validation",
  color_mode="rgb",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

"""## Data Visualisation"""

plt.figure(figsize=(20,5))
plt.bar(class_names,[2000 for i in range(10)],color='orange',alpha=0.5)
plt.xlabel('type')
plt.ylabel('count')
plt.title('Count of Image')

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().flatten().reshape(224,224).astype("uint8"),cmap='gray')
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""## Deep Learning Model - CNN

### AutoEncoding Model
"""

from keras.models import Sequential

model = Sequential()
model.add(Conv2D(32, kernel_size=3, activation="relu", input_shape=(224,224,1)))
model.add(MaxPooling2D())
model.add(Conv2D(64, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(128, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(256, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(512, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(256, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(10,activation="softmax"))

model.summary()

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=20
)

hist_autoenc = pd.DataFrame(history.history)
hist_autoenc['epoch'] = history.epoch
hist_autoenc.tail()

plt.plot(hist_autoenc['accuracy'],marker='x',color='orange')
plt.xlabel('epochs')
plt.ylabel('Training accuracy')
plt.title('Training accuracy variation with epochs')

plt.plot(hist_autoenc['val_accuracy'],marker='x',color='red')
plt.xlabel('epochs')
plt.ylabel('Validation accuracy')
plt.title('Validation accuracy variation with epochs')

plt.plot(hist_autoenc['loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Loss variation with epochs')

"""### VGG-19

"""

from keras.models import Sequential

model = Sequential()
model.add(Conv2D(64, kernel_size=3, activation="relu", input_shape=(224,224,1)))
model.add(MaxPooling2D())
model.add(Conv2D(128, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(256, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Conv2D(512, kernel_size=3, activation="relu"))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(10,activation="softmax"))

model.summary()

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=15
)

hist_vgg19 = pd.DataFrame(history.history)
hist_vgg19['epoch'] = history.epoch
hist_vgg19.tail()

plt.plot(hist_vgg19['accuracy'],marker='x',color='orange')
plt.xlabel('epochs')
plt.ylabel('Training accuracy')
plt.title('Training accuracy variation with epochs')

plt.plot(hist_vgg19['val_accuracy'],marker='x',color='red')
plt.xlabel('epochs')
plt.ylabel('Validation accuracy')
plt.title('Validation accuracy variation with epochs')

plt.plot(hist_vgg19['loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Loss variation with epochs')

pip install pydot

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""### ResNet 50

"""

base_model=tf.keras.applications.resnet50.ResNet50(weights='imagenet',include_top=False)

base_model.summary()

x = base_model.output
x = GlobalMaxPooling2D()(x)
x = Dense(10, activation= 'softmax')(x)
model = Model(inputs = base_model.input, outputs = x)

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

history = model.fit(
  train_ds_normal,
  validation_data=val_ds_normal,
  epochs=15
)

hist_resnet50 = pd.DataFrame(history.history)
hist_resnet50['epoch'] = history.epoch
hist_resnet50.tail()

plt.plot(hist_resnet50['accuracy'],marker='x',color='orange')
plt.xlabel('epochs')
plt.ylabel('Training accuracy')
plt.title('Training accuracy variation with epochs')

plt.plot(hist_resnet50['val_accuracy'],marker='x',color='red')
plt.xlabel('epochs')
plt.ylabel('Validation accuracy')
plt.title('Validation accuracy variation with epochs')

plt.plot(hist_resnet50['loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Loss variation with epochs')



"""### EfficientNet B3"""

base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights="imagenet", input_shape=(224,224,3))

base_model.summary()

model= Sequential()
model.add(base_model) 
model.add(MaxPooling2D())
model.add(Flatten()) 
model.add(Dense(10,activation=('softmax')))

model.summary()

batch_size= 32
epochs=15
learn_rate=.001

sgd=tf.keras.optimizers.SGD(lr=learn_rate,momentum=.9,nesterov=False)

model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds_normal,validation_data=val_ds_normal,epochs=15)

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

plt.plot(hist['accuracy'],marker='x',color='orange')
plt.xlabel('epochs')
plt.ylabel('Training accuracy')
plt.title('Training accuracy variation with epochs')

plt.plot(hist['val_accuracy'],marker='x',color='red')
plt.xlabel('epochs')
plt.ylabel('Validation accuracy')
plt.title('Validation accuracy variation with epochs')

plt.plot(hist['loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Loss variation with epochs')



"""### Implementation present in paper: [Static Hand Gesture Recognition using Convolutional Neural Network with Data Augmentation](https://www.researchgate.net/figure/Sample-Images-from-self-developed-Dataset-Hand-Gesture-Recognition-Database-14-also_fig3_333618617)"""

model = Sequential()

model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.25))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.25))

model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(
  optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.001),
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy']
)

history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=15,
)

hist_cnn = pd.DataFrame(history.history)
hist_cnn['epoch'] = history.epoch
hist_cnn.tail()

plt.plot(hist_cnn['accuracy'],marker='x',color='orange')
plt.xlabel('epochs')
plt.ylabel('Training accuracy')
plt.title('Training accuracy variation with epochs')

plt.plot(hist_cnn['val_accuracy'],marker='x',color='red')
plt.xlabel('epochs')
plt.ylabel('Validation accuracy')
plt.title('Validation accuracy variation with epochs')

plt.plot(hist_cnn['loss'])
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Loss variation with epochs')

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

model.save("cnn_.h5")

model.save("model/CNN.tfl")

model.save_weights("cnn/CNN_.tfl")

# !pip install tensorflowjs
# !tensorflowjs_converter --input_format keras '/content/cnn_.h5' '/content/cnn_'

"""## Comparative Analysis"""

Accuracy_list = [0.995556, 0.971111, 1.0, 0.973333]

Acc_models = ['VGG-19', 'ResNet 50', 'EfficientNet B3', 'CNN']
plt.plot(Acc_models, Accuracy_list, marker ='*') 
plt.title('Accuracy comparison') 
plt.ylabel('Accuracy')
plt.xlabel('Models')
plt.draw() 
plt.show()

losslist = [0.024584, 0.298653, 0.000001, 0.082041]
models = ['VGG-19', 'ResNet 50', 'EfficientNet B3', 'CNN']
plt.plot(models, losslist, marker ='*') 
plt.title('Loss comparison') 
plt.ylabel('Loss')
plt.xlabel('Models')
plt.draw() 
plt.show()